{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size Monotone/Fidelity Testing Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script tests the trained ICCNet/FidNet models with unseen datasets and plots the figures for the manuscript. It is better to run this script from the top down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spi\n",
    "import h5py, hdf5storage\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, merge, Input, ZeroPadding2D, Activation, Add, AveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras import optimizers, regularizers\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid.inset_locator import (inset_axes, InsetPosition,\n",
    "                                                  mark_inset)\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICCNet and FidNet training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=8000 # number of training datasets\n",
    "work_dir='../training/'+str(m)+'_perf_noisy_ex/ICCNet_trained_files/' # directory to trained ICCNet files\n",
    "epochs1 = 1000 # epoch length of ICCNet training\n",
    "\n",
    "Kvec=[4,6,8,10] # choice of K to present.\n",
    "hist_dict={};\n",
    "\n",
    "for l in range(4):\n",
    "    Kbas=Kvec[l]\n",
    "    if Kbas<9:\n",
    "        Xy_dict = spi.loadmat(work_dir+\"model_ICCNet_K_\"+str(Kbas)+\"_Xy.mat\")    \n",
    "    else:\n",
    "        Xy_dict = hdf5storage.loadmat(work_dir+\"model_ICCNet_K_\"+str(Kbas)+\"_Xy.mat\") # due to large MAT filesize\n",
    "\n",
    "    with open(work_dir+\"model_ICCNet_K_\"+str(Kbas)+\"_hist.txt\") as json_file:  \n",
    "            history_ld = json.load(json_file)\n",
    "            \n",
    "    hist_dict['K'+str(Kbas)]=history_ld\n",
    "\n",
    "work_dir2='../training/'+str(m)+'_perf_noisy_ex/FidNet_trained_files/' # directory to trained FidNet files\n",
    "epochs2 = 500 # epoch length of FidNet training\n",
    "\n",
    "Kvec=[4,6,8,10] # choice of K to present.\n",
    "hist_dict2={};\n",
    "\n",
    "for l in range(4):\n",
    "    Kbas=Kvec[l]\n",
    "    if Kbas<9:\n",
    "        Xy_dict = spi.loadmat(work_dir2+\"model_FidNet_K_\"+str(Kbas)+\"_Xy.mat\")    \n",
    "    else:\n",
    "        Xy_dict = hdf5storage.loadmat(work_dir2+\"model_FidNet_K_\"+str(Kbas)+\"_Xy.mat\") # due to large MAT filesize\n",
    "\n",
    "    with open(work_dir2+\"model_FidNet_K_\"+str(Kbas)+\"_hist.txt\") as json_file:  \n",
    "            history_ld = json.load(json_file)\n",
    "            \n",
    "    hist_dict2['K'+str(Kbas)]=history_ld\n",
    "\n",
    "# plots the training and validation graphs for both nets\n",
    "    \n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "labsze=25.5\n",
    "fntsze=30\n",
    "\n",
    "fig,ax = plt.subplots(2,4,figsize=(22,9))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "epochs=epochs1\n",
    "\n",
    "plt.subplot(2, 4, 1)\n",
    "history_ld=hist_dict['K'+str(Kvec[0])]\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['val_loss'],'-',linewidth=4.0)\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['loss'],'--',linewidth=4.0)\n",
    "plt.title(r'$K='+str(Kvec[0])+'$',fontsize=fntsze)\n",
    "plt.xlim([0.9,epochs])\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.legend([r'Validation',r'Training'],loc='best',fontsize=fntsze)\n",
    "plt.tick_params(labelsize=labsze)\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "history_ld=hist_dict['K'+str(Kvec[1])]\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['val_loss'],'-',linewidth=4.0)\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['loss'],'--',linewidth=4.0)\n",
    "plt.title(r'$K='+str(Kvec[1])+'$',fontsize=fntsze)\n",
    "plt.xlim([0.9,epochs])\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.tick_params(labelsize=labsze)\n",
    "\n",
    "plt.subplot(2, 4, 5)\n",
    "history_ld=hist_dict['K'+str(Kvec[2])]\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['val_loss'],'-',linewidth=4.0)\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['loss'],'--',linewidth=4.0)\n",
    "plt.title(r'$K='+str(Kvec[2])+'$',fontsize=fntsze)\n",
    "plt.xlim([0.9,epochs])\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.tick_params(labelsize=labsze)\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "history_ld=hist_dict['K'+str(Kvec[3])]\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['val_loss'],'-',linewidth=4.0)\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['loss'],'--',linewidth=4.0)\n",
    "plt.title(r'$K='+str(Kvec[3])+'$',fontsize=fntsze)\n",
    "plt.xlim([0.9,epochs])\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.tick_params(labelsize=labsze)\n",
    "\n",
    "fig.text(0.32, 0.01, r'ICCNet Training epoch', ha='center',fontsize=fntsze)\n",
    "fig.text(0.07, 0.5, r'Mean absolute-error (MAE)', va='center', rotation='vertical',fontsize=fntsze)\n",
    "\n",
    "epochs=epochs2\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "history_ld=hist_dict2['K'+str(Kvec[0])]\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['val_loss'],'-',linewidth=4.0)\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['loss'],'--',linewidth=4.0)\n",
    "plt.title(r'$K='+str(Kvec[0])+'$',fontsize=fntsze)\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.tick_params(labelsize=labsze)\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "history_ld=hist_dict2['K'+str(Kvec[1])]\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['val_loss'],'-',linewidth=4.0)\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['loss'],'--',linewidth=4.0)\n",
    "plt.title(r'$K='+str(Kvec[1])+'$',fontsize=fntsze)\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.tick_params(labelsize=labsze)\n",
    "\n",
    "plt.subplot(2, 4, 7)\n",
    "history_ld=hist_dict2['K'+str(Kvec[2])]\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['val_loss'],'-',linewidth=4.0)\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['loss'],'--',linewidth=4.0)\n",
    "plt.title(r'$K='+str(Kvec[2])+'$',fontsize=fntsze)\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.tick_params(labelsize=labsze)\n",
    "\n",
    "plt.subplot(2, 4, 8)\n",
    "history_ld=hist_dict2['K'+str(Kvec[3])]\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['val_loss'],'-',linewidth=4.0)\n",
    "plt.plot(np.linspace(1,epochs,epochs),history_ld['loss'],'--',linewidth=4.0)\n",
    "plt.title(r'$K='+str(Kvec[3])+'$',fontsize=fntsze)\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.tick_params(labelsize=labsze)\n",
    "\n",
    "fig.text(0.72, 0.01, r'FidNet Training epoch', ha='center',fontsize=fntsze)\n",
    "fig.text(0.91, 0.5, r'Mean squared-error (MSE)', va='center', rotation='-90',fontsize=fntsze)\n",
    "\n",
    "plt.savefig(\"../training/Fig_ICCNet_FidNet_train_val.pdf\", format='pdf', dpi=1000, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $s_\\text{cvx}$ prediction with unseen simulated test datasets for both ACT and random Haar schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "m=8000 # Sets number of training datasets\n",
    "work_dir='../training/'+str(m)+'_perf_noisy_ex/ICCNet_trained_files/' # Directory to FidNet trained files\n",
    "num_rnks=3 # Sets rank limit.\n",
    "test_dim=16 # Sets Hilbert-space dimension\n",
    "num_test_ex=50 # Sets number of test datasets\n",
    "\n",
    "labels={'0':'_Haar_N_1000','1':'_Haar','2':'_ACT_N_1000','3':'_ACT'}\n",
    "\n",
    "for J in range(4):\n",
    "    \n",
    "    test_dir='../raw_test_examples/test_ex'+labels[str(J)]\n",
    "\n",
    "    Y_dict={}\n",
    "    Y_pred_dict={}\n",
    "\n",
    "    Y=np.ones((num_test_ex,1))\n",
    "    Y_pred=np.ones((num_test_ex,1))\n",
    "    \n",
    "\n",
    "    for l in range(num_rnks):\n",
    "        rnk=l+1\n",
    "        Y_dict['rnk_'+str(rnk)]=Y\n",
    "        Y_pred_dict['rnk_'+str(rnk)]=Y_pred\n",
    "\n",
    "    for k in np.array(np.linspace(2,10,9).astype('int64')):\n",
    "        \n",
    "        print('ex{}: K = {}'.format(labels[str(J)],k))\n",
    "\n",
    "        Xy_dict = spi.loadmat(work_dir+\"model_ICCNet_K_\"+str(k)+\"_Xy.mat\")    \n",
    "        X_orig = Xy_dict['x_train0']\n",
    "\n",
    "        # Loads FidNet model for a given K.\n",
    "        K.clear_session()\n",
    "        model_ld = load_model(work_dir+\"model_ICCNet_K_\"+str(k)+\".h5\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        for l in range(num_rnks):\n",
    "\n",
    "            rnk=l+1\n",
    "            print('processing rnk-{} data...'.format(rnk),end='')\n",
    "\n",
    "            # Loads and preprocesses the test input X matrix into a single-channel image.\n",
    "            X=spi.loadmat(test_dir+'_rnk_'+str(rnk)+'/D'+str(test_dim)+'/proc_data/'+str(num_test_ex)+'_ex/X_'+str(k)+'.mat')['X']       \n",
    "            X=X[:,0:k*(test_dim**2+test_dim)]\n",
    "            X_test=preprocessing.StandardScaler().fit(X_orig).transform(X)\n",
    "\n",
    "            img_rows = int(np.ceil(np.power(X_test.shape[1],0.5)))\n",
    "            img_cols = img_rows\n",
    "            X_test = np.concatenate((X_test,np.zeros((X_test.shape[0],img_rows*img_cols-X_test.shape[1]))),axis=1)\n",
    "            X_test=X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)        \n",
    "\n",
    "            # Loads and stores test fidelity values.\n",
    "            y_cont=np.abs(spi.loadmat(test_dir+'_rnk_'+str(rnk)+'/D'+str(test_dim)+'/proc_data/'+str(num_test_ex)+'_ex/y_cont_'+str(k)+'.mat')['y_cont'])\n",
    "            y_cont=np.abs(y_cont[0:num_test_ex,0]).reshape([num_test_ex,1])\n",
    "            \n",
    "            # Predicts and stores the test fidelity values.\n",
    "            y_pred = model_ld.predict(X_test)\n",
    "            y_pred = np.power(10,-10*y_pred)\n",
    "            \n",
    "            if k==1:\n",
    "                Y_dict['rnk_'+str(rnk)]=y_cont\n",
    "                Y_pred_dict['rnk_'+str(rnk)]=y_pred\n",
    "            else:\n",
    "                Y_dict['rnk_'+str(rnk)]=np.concatenate((Y_dict['rnk_'+str(rnk)],y_cont),axis=1)  \n",
    "                Y_pred_dict['rnk_'+str(rnk)]=np.concatenate((Y_pred_dict['rnk_'+str(rnk)],y_pred),axis=1)\n",
    "                \n",
    "            print('done!')\n",
    "    \n",
    "    spi.savemat(work_dir+\"model_ICCNet_scvx\"+labels[str(J)]+\".mat\", Y_dict)\n",
    "    spi.savemat(work_dir+\"model_ICCNet_scvx_pred\"+labels[str(J)]+\".mat\", Y_pred_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fidelity prediction with unseen simulated test datasets for both ACT and random Haar schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "m=8000 # Sets number of training datasets\n",
    "work_dir='../training/'+str(m)+'_perf_noisy_ex/FidNet_trained_files/' # Directory to FidNet trained files\n",
    "num_rnks=3 # Sets rank limit.\n",
    "test_dim=16 # Sets Hilbert-space dimension\n",
    "num_test_ex=50 # Sets number of test datasets\n",
    "\n",
    "labels={'0':'_Haar_N_1000','1':'_Haar','2':'_ACT_N_1000','3':'_ACT'}\n",
    "\n",
    "for J in range(4):\n",
    "    \n",
    "    test_dir='../raw_test_examples/test_ex'+labels[str(J)]\n",
    "\n",
    "    Y_dict={}\n",
    "    Y_pred_dict={}\n",
    "\n",
    "    Y=np.ones((num_test_ex,1))\n",
    "    Y_pred=np.ones((num_test_ex,1))\n",
    "    \n",
    "\n",
    "    for l in range(num_rnks):\n",
    "        rnk=l+1\n",
    "        Y_dict['rnk_'+str(rnk)]=Y\n",
    "        Y_pred_dict['rnk_'+str(rnk)]=Y_pred\n",
    "\n",
    "    for k in np.array(np.linspace(1,10,10).astype('int64')):\n",
    "        \n",
    "        print('ex{}: K = {}'.format(labels[str(J)],k))\n",
    "\n",
    "        Xy_dict = spi.loadmat(work_dir+\"model_FidNet_K_\"+str(k)+\"_Xy.mat\")    \n",
    "        X_orig = Xy_dict['x_train0']\n",
    "\n",
    "        # Loads FidNet model for a given K.\n",
    "        K.clear_session()\n",
    "        model_ld = load_model(work_dir+\"model_FidNet_K_\"+str(k)+\".h5\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        for l in range(num_rnks):\n",
    "\n",
    "            rnk=l+1\n",
    "            print('processing rnk-{} data...'.format(rnk),end='')\n",
    "\n",
    "            # Loads and preprocesses the test input X matrix into a single-channel image.\n",
    "            X=spi.loadmat(test_dir+'_rnk_'+str(rnk)+'/D'+str(test_dim)+'/proc_data/'+str(num_test_ex)+'_ex/X_'+str(k)+'.mat')['X']       \n",
    "            X_test=preprocessing.StandardScaler().fit(X_orig).transform(X)\n",
    "\n",
    "            img_rows = int(np.ceil(np.power(X_test.shape[1],0.5)))\n",
    "            img_cols = img_rows\n",
    "            X_test = np.concatenate((X_test,np.zeros((X_test.shape[0],img_rows*img_cols-X_test.shape[1]))),axis=1)\n",
    "            X_test=X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)        \n",
    "\n",
    "            # Loads and stores test fidelity values.\n",
    "            y_cont=np.abs(spi.loadmat(test_dir+'_rnk_'+str(rnk)+'/D'+str(test_dim)+'/proc_data/'+str(num_test_ex)+'_ex/y_cont_'+str(k)+'.mat')['y_cont'])\n",
    "            y_cont=np.abs(y_cont[0:num_test_ex,1]).reshape([num_test_ex,1])\n",
    "            \n",
    "            # Predicts and stores the test fidelity values.\n",
    "            y_pred = model_ld.predict(X_test)\n",
    "            \n",
    "            if k==1:\n",
    "                Y_dict['rnk_'+str(rnk)]=y_cont\n",
    "                Y_pred_dict['rnk_'+str(rnk)]=y_pred\n",
    "            else:\n",
    "                Y_dict['rnk_'+str(rnk)]=np.concatenate((Y_dict['rnk_'+str(rnk)],y_cont),axis=1)  \n",
    "                Y_pred_dict['rnk_'+str(rnk)]=np.concatenate((Y_pred_dict['rnk_'+str(rnk)],y_pred),axis=1)\n",
    "                \n",
    "            print('done!')\n",
    "    \n",
    "    spi.savemat(work_dir+\"model_FidNet_fid\"+labels[str(J)]+\".mat\", Y_dict)\n",
    "    spi.savemat(work_dir+\"model_FidNet_fid_pred\"+labels[str(J)]+\".mat\", Y_pred_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots all results in one figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m=8000 # number of training examples\n",
    "work_dir='../training/'+str(m)+'_perf_noisy_ex/ICCNet_trained_files/' # Directory to ICCNet trained files\n",
    "work_dir_fid='../training/'+str(m)+'_perf_noisy_ex/FidNet_trained_files/' # Directory to FidNet trained files\n",
    "\n",
    "rand_or_ACT=1\n",
    "\n",
    "if rand_or_ACT==1:\n",
    "    Y_dict=spi.loadmat(work_dir+\"model_ICCNet_scvx_Haar.mat\")\n",
    "    Y_pred_dict=spi.loadmat(work_dir+\"model_ICCNet_scvx_pred_Haar.mat\")\n",
    "\n",
    "    Y_dict_N=spi.loadmat(work_dir+\"model_ICCNet_scvx_Haar_N_1000.mat\")\n",
    "    Y_pred_dict_N=spi.loadmat(work_dir+\"model_ICCNet_scvx_pred_Haar_N_1000.mat\")\n",
    "    \n",
    "    Y_fid_dict=spi.loadmat(work_dir_fid+\"model_FidNet_fid_Haar.mat\")\n",
    "    Y_fid_pred_dict=spi.loadmat(work_dir_fid+\"model_FidNet_fid_pred_Haar.mat\")\n",
    "\n",
    "    Y_fid_dict_N=spi.loadmat(work_dir_fid+\"model_FidNet_fid_Haar_N_1000.mat\")\n",
    "    Y_fid_pred_dict_N=spi.loadmat(work_dir_fid+\"model_FidNet_fid_pred_Haar_N_1000.mat\")\n",
    "    \n",
    "else:\n",
    "    Y_dict=spi.loadmat(work_dir+\"model_ICCNet_scvx_ACT.mat\")\n",
    "    Y_pred_dict=spi.loadmat(work_dir+\"model_ICCNet_scvx_pred_ACT.mat\")\n",
    "\n",
    "    Y_dict_N=spi.loadmat(work_dir+\"model_ICCNet_scvx_ACT_N_1000.mat\")\n",
    "    Y_pred_dict_N=spi.loadmat(work_dir+\"model_ICCNet_scvx_pred_ACT_N_1000.mat\")\n",
    "    \n",
    "    Y_fid_dict=spi.loadmat(work_dir_fid+\"model_FidNet_fid_ACT.mat\")\n",
    "    Y_fid_pred_dict=spi.loadmat(work_dir_fid+\"model_FidNet_fid_pred_ACT.mat\")\n",
    "\n",
    "    Y_fid_dict_N=spi.loadmat(work_dir_fid+\"model_FidNet_fid_ACT_N_1000.mat\")\n",
    "    Y_fid_pred_dict_N=spi.loadmat(work_dir_fid+\"model_FidNet_fid_pred_ACT_N_1000.mat\")\n",
    "    \n",
    "xrng=np.arange(10)+1\n",
    "\n",
    "labsze=30\n",
    "fntsze=40\n",
    "\n",
    "fig = plt.figure(1,figsize=(18,10))\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.55)\n",
    "\n",
    "for idx in range(3):\n",
    "    Y1=Y_dict['rnk_'+str(idx+1)]\n",
    "    Y1_pred=Y_pred_dict['rnk_'+str(idx+1)]\n",
    "    scvx=np.mean(Y1,axis=0)\n",
    "    scvx_err=np.sqrt(np.var(Y1,axis=0))\n",
    "    scvx_pred=np.mean(Y1_pred,axis=0)\n",
    "    scvx_pred_err=np.sqrt(np.var(Y1_pred,axis=0))\n",
    "    \n",
    "    print('rnk-{} noiseless -log-scvx:'.format(idx+1))     \n",
    "    df = pd.DataFrame({\"actual\": np.abs(np.round(-np.mean(np.log10(Y1[:,1:10]),axis=0),2)),\"pred\":np.abs(np.round(-np.mean(np.log10(Y1_pred[:,1:10]),axis=0),2)),\"avg. mae\":np.abs(np.round(np.mean(np.abs(-np.log10(Y1_pred[:,1:10])+np.log10(Y1[:,1:10])),axis=0),2))})\n",
    "    df.index=np.linspace(2,10,9).astype('int')\n",
    "    print(df[[\"actual\", \"pred\", \"avg. mae\"]].T) \n",
    "\n",
    "    Y1_N=Y_dict_N['rnk_'+str(idx+1)]\n",
    "    Y1_pred_N=Y_pred_dict_N['rnk_'+str(idx+1)]\n",
    "    scvx_N=np.mean(Y1_N,axis=0)\n",
    "    scvx_err_N=np.sqrt(np.var(Y1_N,axis=0))\n",
    "    scvx_pred_N=np.mean(Y1_pred_N,axis=0)\n",
    "    scvx_pred_err_N=np.sqrt(np.var(Y1_pred_N,axis=0))\n",
    "    \n",
    "    print('rnk-{} noisy -log-scvx:'.format(idx+1))\n",
    "    df = pd.DataFrame({\"actual\": np.abs(np.round(-np.mean(np.log10(Y1_N[:,1:10]),axis=0),2)),\"pred\":np.abs(np.round(-np.mean(np.log10(Y1_pred_N[:,1:10]),axis=0),2)),\"avg. mae\":np.abs(np.round(np.mean(np.abs(-np.log10(Y1_pred_N[:,1:10])+np.log10(Y1_N[:,1:10])),axis=0),2))})\n",
    "    df.index=np.linspace(2,10,9).astype('int')\n",
    "    print(df[[\"actual\", \"pred\", \"avg. mae\"]].T) \n",
    "    \n",
    "    ax1 = fig.add_subplot(2,3,idx+1)\n",
    "    if idx==1:\n",
    "        ax1.plot(xrng,scvx,'b^--',linewidth=4.0,markersize=15.0,label='Actual')\n",
    "    else:\n",
    "        ax1.plot(xrng,scvx,'b^--',linewidth=4.0,markersize=15.0)\n",
    "        \n",
    "    ax1.fill_between(xrng,scvx-scvx_err,scvx+scvx_err, interpolate=False,color='b',alpha=0.2)\n",
    "    \n",
    "    if idx==1:\n",
    "        ax1.plot(xrng,scvx_pred,'ro-',linewidth=4.0,markersize=15.0,label='NN')\n",
    "    else:\n",
    "        ax1.plot(xrng,scvx_pred,'ro-',linewidth=4.0,markersize=15.0)\n",
    "            \n",
    "    ax1.fill_between(xrng,scvx_pred-scvx_pred_err,scvx_pred+scvx_pred_err, interpolate=False,color='r',alpha=0.3)\n",
    "    \n",
    "    ax1.set_xlim([-0.1,11])\n",
    "    ax1.set_xlabel(r'$K$',fontsize=fntsze)\n",
    "    ax1.set_ylabel(r'$s_\\mathrm{cvx}$',fontsize=fntsze)\n",
    "    if idx==1:\n",
    "        ax1.legend(loc=1,bbox_to_anchor=(1.1,1.9),fontsize=fntsze,frameon=False)\n",
    "    ax1.set_xticks([2,4,6,8,10])  \n",
    "    ax1.set_yticks([0,0.5,1])  \n",
    "    ax1.set_title(r'$r='+str(idx+1)+'$',fontsize=fntsze)\n",
    "\n",
    "    plt.tick_params(labelsize=labsze)\n",
    "\n",
    "    ax2 = inset_axes(ax1, width=\"50%\",  height=\"50%\")\n",
    "    if idx==0 or idx==1:\n",
    "        ip = InsetPosition(ax1, [0.45,0.45,0.5,0.5])\n",
    "    else:\n",
    "        ip = InsetPosition(ax1, [0.48,0.48,0.5,0.5])\n",
    "    ax2.set_axes_locator(ip)\n",
    "\n",
    "    ax2.plot(xrng,scvx_N,'b^--',linewidth=4.0,markersize=15.0)\n",
    "    ax2.fill_between(xrng,scvx_N-scvx_err_N,scvx_N+scvx_err_N, interpolate=False,color='b',alpha=0.2)\n",
    "    ax2.plot(xrng,scvx_pred_N,'ro-',linewidth=4.0,markersize=15.0)\n",
    "    ax2.fill_between(xrng,scvx_pred_N-scvx_pred_err_N,scvx_pred_N+scvx_pred_err_N, interpolate=False,color='r',alpha=0.3)\n",
    "    ax2.set_xticks([2,4,6,8,10])   \n",
    "    ax2.set_yticks([0,0.5,1])\n",
    "    ax2.set_xlim([-0.1,11])\n",
    "    ax2.set_ylim([-0.1,1.1])\n",
    "    ax2.set_yscale('linear')\n",
    "        \n",
    "    plt.tick_params(labelsize=labsze)\n",
    "    \n",
    "for idx in range(3):\n",
    "    Y=Y_fid_dict['rnk_'+str(idx+1)]\n",
    "    Y_pred=Y_fid_pred_dict['rnk_'+str(idx+1)]\n",
    "    fid=np.mean(Y,axis=0)\n",
    "    fid_err=np.sqrt(np.var(Y,axis=0))\n",
    "    fid_pred=np.mean(Y_pred,axis=0)\n",
    "    fid_pred_err=np.sqrt(np.var(Y_pred,axis=0))\n",
    "    \n",
    "    print('rnk-{} noiseless F'.format(idx+1))\n",
    "    df = pd.DataFrame({\"actual\": np.abs(np.round(-np.mean(Y,axis=0),2)),\"pred\":np.abs(np.round(-np.mean(Y_pred,axis=0),2)),\"avg. mae\":np.abs(np.round(np.mean(np.abs(Y_pred-Y),axis=0),2))})\n",
    "    df.index=np.linspace(1,10,10).astype('int')\n",
    "    print(df[[\"actual\", \"pred\", \"avg. mae\"]].T) \n",
    "\n",
    "    Y_N=Y_fid_dict_N['rnk_'+str(idx+1)]\n",
    "    Y_pred_N=Y_fid_pred_dict_N['rnk_'+str(idx+1)]\n",
    "    fid_N=np.mean(Y_N,axis=0)\n",
    "    fid_err_N=np.sqrt(np.var(Y_N,axis=0))\n",
    "    fid_pred_N=np.mean(Y_pred_N,axis=0)\n",
    "    fid_pred_err_N=np.sqrt(np.var(Y_pred_N,axis=0))\n",
    "    \n",
    "    print('rnk-{} noisy F'.format(idx+1))\n",
    "    df = pd.DataFrame({\"actual\": np.abs(np.round(-np.mean(Y_N,axis=0),2)),\"pred\":np.abs(np.round(-np.mean(Y_pred_N,axis=0),2)),\"avg. mae\":np.abs(np.round(np.mean(np.abs(Y_pred_N-Y_N),axis=0),2))})\n",
    "    df.index=np.linspace(1,10,10).astype('int')\n",
    "    print(df[[\"actual\", \"pred\", \"avg. mae\"]].T) \n",
    "\n",
    "    ax1 = fig.add_subplot(2,3,idx+4)\n",
    "    if idx==1:\n",
    "        ax1.plot(xrng,fid,'b^--',linewidth=4.0,markersize=15.0,label='Actual')\n",
    "    else:\n",
    "        ax1.plot(xrng,fid,'b^--',linewidth=4.0,markersize=15.0)\n",
    "        \n",
    "    ax1.fill_between(xrng,fid-fid_err,fid+fid_err, interpolate=False,color='b',alpha=0.2)\n",
    "    \n",
    "    if idx==1:\n",
    "        ax1.plot(xrng,fid_pred,'ro-',linewidth=4.0,markersize=15.0,label='NN')\n",
    "    else:\n",
    "        ax1.plot(xrng,fid_pred,'ro-',linewidth=4.0,markersize=15.0)\n",
    "            \n",
    "    ax1.fill_between(xrng,fid_pred-fid_pred_err,fid_pred+fid_pred_err, interpolate=False,color='r',alpha=0.3)\n",
    "    \n",
    "    ax1.set_xlim([-0.1,11])\n",
    "    ax1.set_ylim([-0.7,1.1])\n",
    "    ax1.set_xlabel(r'$K$',fontsize=fntsze)\n",
    "    ax1.set_ylabel(r'$\\mathcal{F}$',fontsize=fntsze)\n",
    "    ax1.set_xticks([2,4,6,8,10])  \n",
    "    ax1.set_yticks([0,0.5,1])  \n",
    "    ax1.set_title(r'$r='+str(idx+1)+'$',fontsize=fntsze)\n",
    "\n",
    "    plt.tick_params(labelsize=labsze)\n",
    "\n",
    "    ax2 = inset_axes(ax1, width=\"50%\",  height=\"50%\")\n",
    "    if idx==0 or idx==1:\n",
    "        ip = InsetPosition(ax1, [0.45,0.15,0.5,0.5])\n",
    "    else:\n",
    "        ip = InsetPosition(ax1, [0.48,0.15,0.5,0.5])\n",
    "    ax2.set_axes_locator(ip)\n",
    "\n",
    "    ax2.plot(xrng,fid_N,'b^--',linewidth=4.0,markersize=15.0)\n",
    "    ax2.fill_between(xrng,fid_N-fid_err_N,fid_N+fid_err_N, interpolate=False,color='b',alpha=0.2)\n",
    "    ax2.plot(xrng,fid_pred_N,'ro-',linewidth=4.0,markersize=15.0)\n",
    "    ax2.fill_between(xrng,fid_pred_N-fid_pred_err_N,fid_pred_N+fid_pred_err_N, interpolate=False,color='r',alpha=0.3)\n",
    "    ax2.set_xticks([2,4,6,8,10])   \n",
    "    ax2.set_yticks([0.25,0.5,0.75])  \n",
    "    ax2.set_xlim([-0.1,11])\n",
    "    ax2.set_ylim([-0.1,1.1])\n",
    "    ax2.set_yscale('linear')\n",
    "        \n",
    "    plt.tick_params(labelsize=labsze)\n",
    "    \n",
    "if rand_or_ACT==1:\n",
    "    plt.savefig(\"../training/Fig_Haar_perf_noisy.pdf\", format='pdf', dpi=1000, bbox_inches='tight')\n",
    "else:\n",
    "    plt.savefig(\"../training/Fig_ACT_perf_noisy.pdf\", format='pdf', dpi=1000, bbox_inches='tight')\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ysteo-tensorflow_old",
   "language": "python",
   "name": "ysteo-tensorflow_old"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
